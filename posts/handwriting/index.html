<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.88.1" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark"><title>Working with CNN on MNIST dataset.&nbsp;&ndash;&nbsp;Nived&#39;s Blog</title><link rel="stylesheet" href="/blog/css/core.min.86e97c9ce79d7ff23aa47166ea466e3ce244928ab4d29a809f1f7b896f214f65fc48475a98961c0ee567475b44b7275c.css" integrity="sha384-hul8nOedf/I6pHFm6kZuPOJEkoq00pqAnx97iW8hT2X8SEdamJYcDuVnR1tEtydc"><meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Working with CNN on MNIST dataset." /><body><section id="header">
    <div class="header wrap"><span class="header left-side"><a class="site home" href="/blog/"><span class="site name">Nived's Blog</span></a></span>
        <span class="header right-side"><div class="nav wrap"><nav class="nav"><a class="nav item" href="https://nivedwho%2egithub%2eio/"target="_blank" rel="noopener noreferrer">Website</a></nav></div></span></div></section><section id="content"><div class="article-container"><section class="article header">
    <h1 class="article title">Working with CNN on MNIST dataset.</h1><p class="article date"> </p></section><article class="article markdown-body"><p><strong>September 2020</strong> || Explorting the popular MNIST dataset and implementing a Covolution Neural Network for recognizing hadwritten digits.</p>
<p><a href="https://colab.research.google.com/github/nivedwho/Colab/blob/main/DigitRec.ipynb"target="_blank" rel="noopener noreferrer"><img  src="https://colab.research.google.com/assets/colab-badge.svg"
        alt="Open in Colab"/></a>
</p>
<h3 id="about-the-project">About the project</h3>
<p>The MNIST dataset is a popular containing a large number of images of handwritten digits. The figures shown below are plotted using matplotlib and it shows the number of images per digit in each training and validation set.
<img  src="https://github.com/nivedwho/Images/blob/main/digits.png?raw=true"
        alt="Base Model"/>
<img  src="https://github.com/nivedwho/Images/blob/main/digitsval.png?raw=true"
        alt="Base Model"/>
The training set is labelled, which means that for each image the digit present in the image will be provided as a label. The validation set will not contain these labels and the goal of the CNN model is to predict them with maximum accuracy.</p>
<h3 id="convolution-network">Convolution network</h3>
<p>The model was implemented using Keras and the model is a sequential model. The model consists of :-</p>
<ul>
<li>2 Convolutional Blocks - Contains a 2 <a href="https://keras.io/api/layers/convolution_layers/convolution2d/"target="_blank" rel="noopener noreferrer">Conv2D</a>
 layers with <a href="https://keras.io/api/layers/activation_layers/leaky_relu/"target="_blank" rel="noopener noreferrer">LeakyReLu</a>
 as activation layer, <a href="https://keras.io/api/layers/pooling_layers/max_pooling2d/"target="_blank" rel="noopener noreferrer">MaxPool2D</a>
 layer and a <a href="https://keras.io/api/layers/core_layers/#dropout"target="_blank" rel="noopener noreferrer">Dropout layer</a>
.</li>
<li>Flatten Layer</li>
<li>Dense Layer</li>
<li>And finally the Output layer</li>
</ul>
<p>What are all these you ask? Well the job of the network is to understand the basic trait of each digit, a feature that will be common irrespective of the style of handwriting. Now all these mentioned layers are a part of this process and read more about each layer and its  functionalities <a href="https://www.upgrad.com/blog/basic-cnn-architecture/"target="_blank" rel="noopener noreferrer">here</a>
.</p>
<p><img  src="https://github.com/nivedwho/Images/blob/main/CNNArch.png?raw=true"
        alt="Base Model"/></p>
<p>After this the learning rate is set to 0.001, sparce_categorical_crossentropy is used as the loss function and the optimizer for the network is set as adam.</p>
<p>Once this much is done training can be started. The below plot shows the increase in accuracy and decrease in loss value with training time.
<img  src="https://github.com/nivedwho/Images/blob/main/PlotCNN.png?raw=true"
        alt="Base Model"/></p>
<p>After training the model can be predict the labels in the validation set and subsequently accuracy can also be obtained.</p>
<p><a href="https://colab.research.google.com/github/nivedwho/Colab/blob/main/DigitRec.ipynb"target="_blank" rel="noopener noreferrer"><img  src="https://colab.research.google.com/assets/colab-badge.svg"
        alt="Open in Colab"/></a>
</p></article><section class="article labels"><a class="category" href=/blog/categories/computer-vision/>Computer Vision</a><a class="category" href=/blog/categories/mnist/>MNIST</a><a class="category" href=/blog/categories/cnn/>CNN</a></section>
</div>
<div class="article bottom"><section class="article navigation"><p><a class="link" href="/blog/posts/srgan/"><span class="iconfont icon-article"></span>Using GANs for Single Image Super Resolution</a></p><p><a class="link" href="/blog/posts/masking/"><span class="iconfont icon-article"></span>Protecting privacy using PyTesseract</a></p></section></div></section><section id="footer"><div class="footer-wrap">
    <p class="copyright">Nived's Blog</p>
    <p class="powerby"><span>Powered&nbsp;by&nbsp;</span><a href="https://gohugo.io" 
        target="_blank" rel="noopener noreferrer">Hugo</a><span>&nbsp;&amp;&nbsp;</span><a href="https://themes.gohugo.io/hugo-notepadium/" 
        target="_blank" rel="noopener noreferrer">Notepadium</a></p></div>
</section></body>

</html>